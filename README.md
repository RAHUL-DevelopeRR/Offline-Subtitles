# Offline Subtitle Generator ðŸŽ¬

A fully **offline**, **CPU-optimized** subtitle generation system that combines
**speech recognition** (Faster-Whisper) and **sound event detection** (YAMNet)
to produce rich `.srt` subtitle files with contextual captions.

## Features

- ðŸ—£ï¸ **Speech-to-Text** â€” Accurate transcription using Faster-Whisper (INT8 quantized)
- ðŸ”Š **Sound Event Captions** â€” Detects 60+ sound events (door slams, crying, engines, etc.)
- ðŸ§  **Smart Segmentation** â€” Silero VAD separates speech from non-speech regions
- âš¡ **CPU Optimized** â€” INT8 quantization, VAD-based skip, voluntary CPU throttling
- ðŸ’¾ **Result Caching** â€” Skip re-processing unchanged files
- ðŸ”Œ **100% Offline** â€” No cloud APIs, no internet required after setup

## Quick Start

### 1. Install Dependencies

```bash
# Create virtual environment (recommended)
python -m venv venv
venv\Scripts\activate        # Windows
source venv/bin/activate     # Linux/macOS

# Install Python packages
pip install -r requirements.txt
```

### 2. Install FFmpeg

- **Windows:** Download from [ffmpeg.org](https://ffmpeg.org/download.html), add to PATH
- **Linux:** `sudo apt install ffmpeg`
- **macOS:** `brew install ffmpeg`

### 3. Download Models

See [models/README.md](models/README.md) for download instructions.

### 4. Generate Subtitles

```bash
# Basic usage â€” generates movie.srt alongside the video
python main.py movie.mp4

# Custom output path
python main.py movie.mp4 -o subtitles.srt

# Use faster (but less accurate) model
python main.py movie.mp4 --model base

# Parallel processing (faster, higher CPU)
python main.py movie.mp4 --parallel

# Force language detection
python main.py movie.mp4 --language en

# Allow higher CPU usage
python main.py movie.mp4 --max-cpu 80

# Verbose logging
python main.py movie.mp4 -v
```

## Architecture

```
Video File â†’ Audio Extract â†’ VAD Segment â†’ ASR + SED â†’ Merge â†’ .srt
               (FFmpeg)      (Silero)     (Whisper)   (YAMNet)
                                          (parallel/sequential)
```

| Stage | Time (10 min video) | CPU | RAM |
|---|---|---|---|
| Audio extraction | 2â€“5 sec | 10â€“20% | 50 MB |
| VAD segmentation | 1â€“3 sec | 15â€“25% | 30 MB |
| ASR (Whisper small INT8) | 3â€“4 min | 50â€“70% | 600 MB |
| Sound event detection | 5â€“15 sec | 20â€“40% | 50 MB |
| **Total** | **~4â€“5 min** | **Peak 70%** | **~880 MB** |

## Configuration

Edit `config.yaml` to adjust:
- Model size (`tiny` / `base` / `small`)
- CPU usage limit
- Confidence thresholds
- Threading mode (sequential/parallel)
- VAD sensitivity

## Project Structure

```
offline-subtitles/
â”œâ”€â”€ main.py                # CLI entry point
â”œâ”€â”€ config.py              # Configuration loader
â”œâ”€â”€ config.yaml            # Settings
â”œâ”€â”€ requirements.txt       # Dependencies
â”œâ”€â”€ pipeline/              # Core modules
â”‚   â”œâ”€â”€ orchestrator.py    # Pipeline coordinator
â”‚   â”œâ”€â”€ audio_extractor.py # FFmpeg wrapper
â”‚   â”œâ”€â”€ vad.py             # Silero VAD
â”‚   â”œâ”€â”€ asr_worker.py      # Faster-Whisper ASR
â”‚   â”œâ”€â”€ sed_worker.py      # YAMNet SED
â”‚   â”œâ”€â”€ merger.py          # Timeline merger
â”‚   â”œâ”€â”€ srt_writer.py      # SRT formatter
â”‚   â””â”€â”€ cpu_throttle.py    # CPU limiter
â”œâ”€â”€ models/                # Model files
â”œâ”€â”€ cache/                 # Processing cache
â””â”€â”€ tests/                 # Unit tests
```

## Output Example

```srt
1
00:00:01,200 --> 00:00:04,800
Hello everyone, welcome to the show.

2
00:00:05,100 --> 00:00:06,300
(Audience clapping)

3
00:00:06,500 --> 00:00:10,200
Today we're going to talk about something amazing.

4
00:00:10,500 --> 00:00:11,800
(Door slams)
```

## Requirements

- **Python** 3.10+
- **FFmpeg** (system-installed)
- **Hardware:** Intel i5 class CPU, 8+ GB RAM
- **Disk:** ~200 MB for models
- **No GPU required**

## License

MIT
